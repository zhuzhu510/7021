{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48d7925c-ba05-4308-b453-076968fb34cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.11/site-packages (4.46.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.25.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.11/site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2024.8.30)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.11/site-packages (3.0.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from datasets) (3.16.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from datasets) (1.24.3)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.11/site-packages (from datasets) (17.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.11/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.11/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.11/site-packages (from datasets) (4.66.4)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.11/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.11/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /opt/conda/lib/python3.11/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.11/site-packages (from datasets) (3.10.9)\n",
      "Requirement already satisfied: huggingface-hub>=0.22.0 in /opt/conda/lib/python3.11/site-packages (from datasets) (0.25.2)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from datasets) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (1.14.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.22.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/conda/lib/python3.11/site-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: textattack in /opt/conda/lib/python3.11/site-packages (0.3.10)\n",
      "Requirement already satisfied: bert-score>=0.3.5 in /opt/conda/lib/python3.11/site-packages (from textattack) (0.3.13)\n",
      "Requirement already satisfied: editdistance in /opt/conda/lib/python3.11/site-packages (from textattack) (0.8.1)\n",
      "Requirement already satisfied: flair in /opt/conda/lib/python3.11/site-packages (from textattack) (0.14.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from textattack) (3.16.1)\n",
      "Requirement already satisfied: language-tool-python in /opt/conda/lib/python3.11/site-packages (from textattack) (2.8.1)\n",
      "Requirement already satisfied: lemminflect in /opt/conda/lib/python3.11/site-packages (from textattack) (0.2.3)\n",
      "Requirement already satisfied: lru-dict in /opt/conda/lib/python3.11/site-packages (from textattack) (1.3.0)\n",
      "Requirement already satisfied: datasets>=2.4.0 in /opt/conda/lib/python3.11/site-packages (from textattack) (3.0.1)\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.11/site-packages (from textattack) (3.9.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /opt/conda/lib/python3.11/site-packages (from textattack) (1.24.3)\n",
      "Requirement already satisfied: pandas>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from textattack) (2.2.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /opt/conda/lib/python3.11/site-packages (from textattack) (1.14.1)\n",
      "Requirement already satisfied: torch!=1.8,>=1.7.0 in /opt/conda/lib/python3.11/site-packages (from textattack) (2.3.0+das.opt1.dtk24042)\n",
      "Requirement already satisfied: transformers>=4.30.0 in /opt/conda/lib/python3.11/site-packages (from textattack) (4.46.3)\n",
      "Requirement already satisfied: terminaltables in /opt/conda/lib/python3.11/site-packages (from textattack) (3.1.10)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from textattack) (4.66.4)\n",
      "Requirement already satisfied: word2number in /opt/conda/lib/python3.11/site-packages (from textattack) (1.1)\n",
      "Requirement already satisfied: num2words in /opt/conda/lib/python3.11/site-packages (from textattack) (0.5.13)\n",
      "Requirement already satisfied: more-itertools in /opt/conda/lib/python3.11/site-packages (from textattack) (10.5.0)\n",
      "Requirement already satisfied: pinyin>=0.4.0 in /opt/conda/lib/python3.11/site-packages (from textattack) (0.4.0)\n",
      "Requirement already satisfied: jieba in /opt/conda/lib/python3.11/site-packages (from textattack) (0.42.1)\n",
      "Requirement already satisfied: OpenHowNet in /opt/conda/lib/python3.11/site-packages (from textattack) (2.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from bert-score>=0.3.5->textattack) (2.32.3)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.11/site-packages (from bert-score>=0.3.5->textattack) (3.9.2)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.11/site-packages (from bert-score>=0.3.5->textattack) (24.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.11/site-packages (from datasets>=2.4.0->textattack) (17.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.11/site-packages (from datasets>=2.4.0->textattack) (0.3.8)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.11/site-packages (from datasets>=2.4.0->textattack) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.11/site-packages (from datasets>=2.4.0->textattack) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /opt/conda/lib/python3.11/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets>=2.4.0->textattack) (2024.6.1)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.11/site-packages (from datasets>=2.4.0->textattack) (3.10.9)\n",
      "Requirement already satisfied: huggingface-hub>=0.22.0 in /opt/conda/lib/python3.11/site-packages (from datasets>=2.4.0->textattack) (0.25.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from datasets>=2.4.0->textattack) (6.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas>=1.0.1->textattack) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas>=1.0.1->textattack) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas>=1.0.1->textattack) (2024.2)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.11/site-packages (from torch!=1.8,>=1.7.0->textattack) (4.12.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch!=1.8,>=1.7.0->textattack) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch!=1.8,>=1.7.0->textattack) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch!=1.8,>=1.7.0->textattack) (3.1.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers>=4.30.0->textattack) (2024.9.11)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.11/site-packages (from transformers>=4.30.0->textattack) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.11/site-packages (from transformers>=4.30.0->textattack) (0.4.5)\n",
      "Requirement already satisfied: boto3>=1.20.27 in /opt/conda/lib/python3.11/site-packages (from flair->textattack) (1.35.65)\n",
      "Requirement already satisfied: conllu<5.0.0,>=4.0 in /opt/conda/lib/python3.11/site-packages (from flair->textattack) (4.5.3)\n",
      "Requirement already satisfied: deprecated>=1.2.13 in /opt/conda/lib/python3.11/site-packages (from flair->textattack) (1.2.15)\n",
      "Requirement already satisfied: ftfy>=6.1.0 in /opt/conda/lib/python3.11/site-packages (from flair->textattack) (6.3.1)\n",
      "Requirement already satisfied: gdown>=4.4.0 in /opt/conda/lib/python3.11/site-packages (from flair->textattack) (5.2.0)\n",
      "Requirement already satisfied: langdetect>=1.0.9 in /opt/conda/lib/python3.11/site-packages (from flair->textattack) (1.0.9)\n",
      "Requirement already satisfied: lxml>=4.8.0 in /opt/conda/lib/python3.11/site-packages (from flair->textattack) (5.3.0)\n",
      "Requirement already satisfied: mpld3>=0.3 in /opt/conda/lib/python3.11/site-packages (from flair->textattack) (0.5.10)\n",
      "Requirement already satisfied: pptree>=3.1 in /opt/conda/lib/python3.11/site-packages (from flair->textattack) (3.1)\n",
      "Requirement already satisfied: pytorch-revgrad>=0.2.0 in /opt/conda/lib/python3.11/site-packages (from flair->textattack) (0.2.0)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in /opt/conda/lib/python3.11/site-packages (from flair->textattack) (1.5.2)\n",
      "Requirement already satisfied: segtok>=1.5.11 in /opt/conda/lib/python3.11/site-packages (from flair->textattack) (1.5.11)\n",
      "Requirement already satisfied: sqlitedict>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from flair->textattack) (2.1.0)\n",
      "Requirement already satisfied: tabulate>=0.8.10 in /opt/conda/lib/python3.11/site-packages (from flair->textattack) (0.9.0)\n",
      "Requirement already satisfied: transformer-smaller-training-vocab>=0.2.3 in /opt/conda/lib/python3.11/site-packages (from flair->textattack) (0.4.0)\n",
      "Requirement already satisfied: wikipedia-api>=0.5.7 in /opt/conda/lib/python3.11/site-packages (from flair->textattack) (0.7.1)\n",
      "Requirement already satisfied: semver<4.0.0,>=3.0.0 in /opt/conda/lib/python3.11/site-packages (from flair->textattack) (3.0.2)\n",
      "Requirement already satisfied: bioc<3.0.0,>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from flair->textattack) (2.1)\n",
      "Requirement already satisfied: pip in /opt/conda/lib/python3.11/site-packages (from language-tool-python->textattack) (24.2)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.11/site-packages (from language-tool-python->textattack) (0.43.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.11/site-packages (from nltk->textattack) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.11/site-packages (from nltk->textattack) (1.4.2)\n",
      "Requirement already satisfied: docopt>=0.6.2 in /opt/conda/lib/python3.11/site-packages (from num2words->textattack) (0.6.2)\n",
      "Requirement already satisfied: anytree in /opt/conda/lib/python3.11/site-packages (from OpenHowNet->textattack) (2.12.1)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.11/site-packages (from OpenHowNet->textattack) (72.1.0)\n",
      "Requirement already satisfied: jsonlines>=1.2.0 in /opt/conda/lib/python3.11/site-packages (from bioc<3.0.0,>=2.0.0->flair->textattack) (4.0.0)\n",
      "Requirement already satisfied: intervaltree in /opt/conda/lib/python3.11/site-packages (from bioc<3.0.0,>=2.0.0->flair->textattack) (3.1.0)\n",
      "Requirement already satisfied: botocore<1.36.0,>=1.35.65 in /opt/conda/lib/python3.11/site-packages (from boto3>=1.20.27->flair->textattack) (1.35.65)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.11/site-packages (from boto3>=1.20.27->flair->textattack) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /opt/conda/lib/python3.11/site-packages (from boto3>=1.20.27->flair->textattack) (0.10.3)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /opt/conda/lib/python3.11/site-packages (from deprecated>=1.2.13->flair->textattack) (1.16.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.4.0->textattack) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.4.0->textattack) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.4.0->textattack) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.4.0->textattack) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.4.0->textattack) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.4.0->textattack) (1.14.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.11/site-packages (from ftfy>=6.1.0->flair->textattack) (0.2.13)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.11/site-packages (from gdown>=4.4.0->flair->textattack) (4.12.3)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.11/site-packages (from langdetect>=1.0.9->flair->textattack) (1.16.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib->bert-score>=0.3.5->textattack) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.11/site-packages (from matplotlib->bert-score>=0.3.5->textattack) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib->bert-score>=0.3.5->textattack) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib->bert-score>=0.3.5->textattack) (1.4.7)\n",
      "Requirement already satisfied: pillow>=8 in /opt/conda/lib/python3.11/site-packages (from matplotlib->bert-score>=0.3.5->textattack) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib->bert-score>=0.3.5->textattack) (3.1.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->bert-score>=0.3.5->textattack) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->bert-score>=0.3.5->textattack) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->bert-score>=0.3.5->textattack) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->bert-score>=0.3.5->textattack) (2024.8.30)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn>=1.0.2->flair->textattack) (3.5.0)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /opt/conda/lib/python3.11/site-packages (from transformers[sentencepiece]<5.0.0,>=4.18.0->flair->textattack) (0.2.0)\n",
      "Requirement already satisfied: protobuf in /opt/conda/lib/python3.11/site-packages (from transformers[sentencepiece]<5.0.0,>=4.18.0->flair->textattack) (5.28.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch!=1.8,>=1.7.0->textattack) (3.0.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy->torch!=1.8,>=1.7.0->textattack) (1.3.0)\n",
      "Requirement already satisfied: accelerate>=0.26.0 in /opt/conda/lib/python3.11/site-packages (from transformers[sentencepiece,torch]<5.0,>=4.1->transformer-smaller-training-vocab>=0.2.3->flair->textattack) (1.1.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/conda/lib/python3.11/site-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets>=2.4.0->textattack) (0.2.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.11/site-packages (from beautifulsoup4->gdown>=4.4.0->flair->textattack) (2.6)\n",
      "Requirement already satisfied: sortedcontainers<3.0,>=2.0 in /opt/conda/lib/python3.11/site-packages (from intervaltree->bioc<3.0.0,>=2.0.0->flair->textattack) (2.4.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.11/site-packages (from requests[socks]->gdown>=4.4.0->flair->textattack) (1.7.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from accelerate>=0.26.0->transformers[sentencepiece,torch]<5.0,>=4.1->transformer-smaller-training-vocab>=0.2.3->flair->textattack) (6.0.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install datasets\n",
    "!pip install textattack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "473e309e-91d7-4e43-8b6d-551dd687261a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: wandb in /opt/conda/lib/python3.11/site-packages (0.18.7)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /opt/conda/lib/python3.11/site-packages (from wandb) (8.1.7)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.11/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.11/site-packages (from wandb) (3.1.43)\n",
      "Requirement already satisfied: platformdirs in /opt/conda/lib/python3.11/site-packages (from wandb) (3.10.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /opt/conda/lib/python3.11/site-packages (from wandb) (5.28.2)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.11/site-packages (from wandb) (6.0.0)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.11/site-packages (from wandb) (6.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from wandb) (2.32.3)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from wandb) (2.18.0)\n",
      "Requirement already satisfied: setproctitle in /opt/conda/lib/python3.11/site-packages (from wandb) (1.3.4)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.11/site-packages (from wandb) (72.1.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4 in /opt/conda/lib/python3.11/site-packages (from wandb) (4.12.2)\n",
      "Requirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.11/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.11/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.0.0->wandb) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.0.0->wandb) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.0.0->wandb) (2024.8.30)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1366b0b2-8270-4ef2-924d-70b87b6aa4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import load_dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9c5896a-7853-493e-992a-b1c1f5c67d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "# ä¸‹è½½WordNet\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c782b4fb-a829-4d3a-97e4-b57a61b97e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# 1. åŠ è½½ IMDB æ•°æ®é›†\n",
    "dataset = load_dataset(\"imdb\")\n",
    "# Load model and tokenizer\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "# Tokenization function with max_length and padding\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch['text'], padding='max_length', truncation=True, max_length=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b387940-d092-48ba-8487-0ca1c46f91df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the dataset\n",
    "dataset = dataset.map(tokenize, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e552d78-f242-40ff-889f-5c0ff7433615",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    }
   ],
   "source": [
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=3,               # å¢åŠ è®­ç»ƒè½®æ•°\n",
    "    per_device_train_batch_size=32,   # å¢åŠ æ‰¹é‡å¤§å°\n",
    "    per_device_eval_batch_size=64,    # å¢åŠ è¯„ä¼°æ‰¹é‡å¤§å°\n",
    "    warmup_steps=500,                  # å¢åŠ é¢„çƒ­æ­¥æ•°\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=20,                  # å¢åŠ æ—¥å¿—è®°å½•é¢‘ç‡\n",
    "    evaluation_strategy=\"epoch\",       # æ¯ä¸ªepochè¿›è¡Œè¯„ä¼°\n",
    "    save_steps=1000,                   # å¢åŠ ä¿å­˜æ­¥æ•°\n",
    "    eval_steps=500,                    # å¢åŠ è¯„ä¼°æ­¥æ•°\n",
    "    learning_rate=5e-5,                # æ·»åŠ å­¦ä¹ ç‡å‚æ•°                  # Increased eval steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "806a9373-1f3a-4320-ba65-89868fe53875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define compute metrics function\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = logits.argmax(axis=-1)\n",
    "    \n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    precision = precision_score(labels, predictions, average='weighted')\n",
    "    recall = recall_score(labels, predictions, average='weighted')\n",
    "    f1 = f1_score(labels, predictions, average='weighted')\n",
    "    \n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "485c3f22-7d78-4fbc-846d-add87a18b847",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-11-21 17:59:40,312] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:440: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at /data/jenkins_workspace/workspace/pytorch@4/aten/src/ATen/native/transformers/hip/sdp_utils.cpp:459.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "/opt/conda/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:440: UserWarning: 1Torch was not compiled with memory efficient attention. (Triggered internally at /data/jenkins_workspace/workspace/pytorch@4/aten/src/ATen/native/transformers/hip/sdp_utils.cpp:508.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2346' max='2346' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2346/2346 20:22, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.231400</td>\n",
       "      <td>0.263557</td>\n",
       "      <td>0.891240</td>\n",
       "      <td>0.897617</td>\n",
       "      <td>0.891240</td>\n",
       "      <td>0.890802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.174200</td>\n",
       "      <td>0.203964</td>\n",
       "      <td>0.922200</td>\n",
       "      <td>0.922679</td>\n",
       "      <td>0.922200</td>\n",
       "      <td>0.922178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.054000</td>\n",
       "      <td>0.291936</td>\n",
       "      <td>0.923360</td>\n",
       "      <td>0.923435</td>\n",
       "      <td>0.923360</td>\n",
       "      <td>0.923357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2346, training_loss=0.18716185125510407, metrics={'train_runtime': 1229.945, 'train_samples_per_second': 60.978, 'train_steps_per_second': 1.907, 'total_flos': 9866664576000000.0, 'train_loss': 0.18716185125510407, 'epoch': 3.0})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a Trainer instance\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset['train'],  # Use small subset here\n",
    "    eval_dataset=dataset['test'],\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Start model training\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e91a8fb5-90d3-46f6-a9e1-a577422ed5d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='391' max='391' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [391/391 01:39]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation results:\n",
      "eval_loss: 0.2919\n",
      "eval_accuracy: 0.9234\n",
      "eval_precision: 0.9234\n",
      "eval_recall: 0.9234\n",
      "eval_f1: 0.9234\n",
      "eval_runtime: 99.3973\n",
      "eval_samples_per_second: 251.5160\n",
      "eval_steps_per_second: 3.9340\n",
      "epoch: 3.0000\n"
     ]
    }
   ],
   "source": [
    "eval_results = trainer.evaluate()\n",
    "\n",
    "# Print evaluation results\n",
    "print(\"\\nEvaluation results:\")\n",
    "for key, value in eval_results.items():\n",
    "    print(f\"{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eafdca7e-e8cc-4511-8899-6badfe3a15f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2346' max='2346' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2346/2346 38:07, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.054600</td>\n",
       "      <td>0.303120</td>\n",
       "      <td>0.914600</td>\n",
       "      <td>0.914857</td>\n",
       "      <td>0.914600</td>\n",
       "      <td>0.914587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.046200</td>\n",
       "      <td>0.357199</td>\n",
       "      <td>0.918400</td>\n",
       "      <td>0.918584</td>\n",
       "      <td>0.918400</td>\n",
       "      <td>0.918391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.026700</td>\n",
       "      <td>0.425629</td>\n",
       "      <td>0.922400</td>\n",
       "      <td>0.922496</td>\n",
       "      <td>0.922400</td>\n",
       "      <td>0.922396</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2346, training_loss=0.046725945998989965, metrics={'train_runtime': 2288.3091, 'train_samples_per_second': 32.775, 'train_steps_per_second': 1.025, 'total_flos': 9866664576000000.0, 'train_loss': 0.046725945998989965, 'epoch': 3.0})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "import torch\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "class AdversarialTrainer(Trainer):\n",
    "    def __init__(self, *args, epsilon=0.1, alpha=0.5, **kwargs):\n",
    "        \"\"\"\n",
    "        åˆå§‹åŒ–å¯¹æŠ—è®­ç»ƒå™¨\n",
    "        :param epsilon: å¯¹æŠ—æ‰°åŠ¨çš„å¼ºåº¦\n",
    "        :param alpha: æ­£å¸¸æŸå¤±ä¸å¯¹æŠ—æŸå¤±çš„æƒé‡\n",
    "        \"\"\"\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.epsilon = epsilon  # å¯¹æŠ—æ‰°åŠ¨çš„å¼ºåº¦\n",
    "        self.alpha = alpha      # æ­£å¸¸æŸå¤±ä¸å¯¹æŠ—æŸå¤±çš„åŠ æƒç³»æ•°\n",
    "        self.training = True    # æ ‡è®°å½“å‰æ˜¯å¦åœ¨è®­ç»ƒæ¨¡å¼\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
    "        \"\"\"\n",
    "        è®¡ç®—æŸå¤±\n",
    "        :param model: è®­ç»ƒçš„æ¨¡å‹\n",
    "        :param inputs: è¾“å…¥æ•°æ®ï¼ŒåŒ…æ‹¬ input_idsã€labels å’Œ attention_mask\n",
    "        :param return_outputs: æ˜¯å¦è¿”å›æ¨¡å‹è¾“å‡º\n",
    "        :param num_items_in_batch: æ¯ä¸ªæ‰¹æ¬¡çš„æ ·æœ¬æ•°é‡\n",
    "        :return: è®¡ç®—å¾—åˆ°çš„æ€»æŸå¤±\n",
    "        \"\"\"\n",
    "        input_ids = inputs.get(\"input_ids\")  # è·å–è¾“å…¥çš„ ID\n",
    "        labels = inputs.get(\"labels\")          # è·å–æ ‡ç­¾\n",
    "        attention_mask = inputs.get(\"attention_mask\")  # è·å–æ³¨æ„åŠ›æ©ç \n",
    "\n",
    "        # æ­£å¸¸å‰å‘ä¼ æ’­ï¼Œè®¡ç®—æ­£å¸¸æŸå¤±\n",
    "        outputs = model(**inputs)\n",
    "        normal_loss = outputs.loss\n",
    "\n",
    "        if self.training:\n",
    "            # è·å–è¾“å…¥åµŒå…¥å¹¶è®¾ç½®ä¸ºå¯æ±‚å¯¼\n",
    "            embeddings = model.get_input_embeddings()(input_ids).detach()\n",
    "            embeddings.requires_grad = True\n",
    "\n",
    "            # è®¡ç®—å¯¹æŠ—è¾“å‡º\n",
    "            adv_outputs = model(inputs_embeds=embeddings, attention_mask=attention_mask)\n",
    "            adv_loss = CrossEntropyLoss()(adv_outputs.logits, labels)  # è®¡ç®—å¯¹æŠ—æŸå¤±\n",
    "\n",
    "            # è®¡ç®—æ€»æŸå¤±ï¼Œç»“åˆæ­£å¸¸æŸå¤±å’Œå¯¹æŠ—æŸå¤±\n",
    "            total_loss = (1 - self.alpha) * normal_loss + self.alpha * adv_loss\n",
    "        else:\n",
    "            total_loss = normal_loss  # å¦‚æœä¸æ˜¯è®­ç»ƒæ¨¡å¼ï¼Œä»…è¿”å›æ­£å¸¸æŸå¤±\n",
    "\n",
    "        return (total_loss, outputs) if return_outputs else total_loss  # æ ¹æ®éœ€è¦è¿”å›æŸå¤±å’Œè¾“å‡º\n",
    "\n",
    "# ä½¿ç”¨æ–°çš„è®­ç»ƒå‚æ•°\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=3,               # å¢åŠ è®­ç»ƒè½®æ•°\n",
    "    per_device_train_batch_size=32,   # å¢åŠ æ‰¹é‡å¤§å°\n",
    "    per_device_eval_batch_size=64,    # å¢åŠ è¯„ä¼°æ‰¹é‡å¤§å°\n",
    "    warmup_steps=500,                  # å¢åŠ é¢„çƒ­æ­¥æ•°\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=20,                  # å¢åŠ æ—¥å¿—è®°å½•é¢‘ç‡\n",
    "    evaluation_strategy=\"epoch\",       # æ¯ä¸ªepochè¿›è¡Œè¯„ä¼°\n",
    "    save_steps=1000,                   # å¢åŠ ä¿å­˜æ­¥æ•°\n",
    "    eval_steps=500,                    # å¢åŠ è¯„ä¼°æ­¥æ•°\n",
    "    learning_rate=5e-5,                # æ·»åŠ å­¦ä¹ ç‡å‚æ•°                  # Increased eval steps\n",
    ")\n",
    "\n",
    "# åˆ›å»ºè®­ç»ƒå™¨\n",
    "trainer = AdversarialTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset['train'],\n",
    "    eval_dataset=dataset['test'],\n",
    "    compute_metrics=compute_metrics,\n",
    "\n",
    ")\n",
    "\n",
    "# å¼€å§‹è®­ç»ƒ\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13a32c81-611d-4a90-9918-c36f774a2fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 3. å®šä¹‰æ›¿æ¢åŒä¹‰è¯çš„å‡½æ•°\n",
    "def get_synonyms(word):\n",
    "    synonyms = set()\n",
    "    for syn in wordnet.synsets(word):\n",
    "        for lemma in syn.lemmas():\n",
    "            synonyms.add(lemma.name())  # æ·»åŠ åŒä¹‰è¯\n",
    "    return list(synonyms)\n",
    "\n",
    "def replace_with_synonyms(text):\n",
    "    words = text.split()\n",
    "    modified_words = []\n",
    "    \n",
    "    for word in words:\n",
    "        if np.random.rand() < 0.2:  # 20% æ¦‚ç‡æ›¿æ¢å•è¯\n",
    "            synonyms = get_synonyms(word)\n",
    "            if synonyms:\n",
    "                word = np.random.choice(synonyms)  # éšæœºé€‰æ‹©ä¸€ä¸ªåŒä¹‰è¯\n",
    "        modified_words.append(word)\n",
    "        \n",
    "    return ' '.join(modified_words)\n",
    "\n",
    "# 4. å®šä¹‰ç”Ÿæˆå¯¹æŠ—æ ·æœ¬çš„å‡½æ•°ï¼ˆä½¿ç”¨æ›¿æ¢åŒä¹‰è¯ï¼‰\n",
    "def generate_adversarial_sample_with_replacement(text):\n",
    "    modified_text = replace_with_synonyms(text)  # ä½¿ç”¨åŒä¹‰è¯æ›¿æ¢\n",
    "    return modified_text\n",
    "\n",
    "# 5. ç”Ÿæˆå¯¹æŠ—æ ·æœ¬å¹¶ä¸ IMDB æ•°æ®ç»“åˆ\n",
    "adversarial_samples = []\n",
    "\n",
    "for review in dataset['train']['text']:  \n",
    "    adversarial_sample = generate_adversarial_sample_with_replacement(review)\n",
    "    adversarial_samples.append(adversarial_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a2c399f6-1ad7-4b0b-8dde-130dda5635a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "# 6. ç”¨åŸå§‹æ ‡ç­¾åˆ›å»ºæ–°çš„æ•°æ®é›†\n",
    "original_labels = dataset['train']['label']  # å¯¹åº”çš„åŸå§‹æ ‡ç­¾\n",
    "combined_texts = dataset['train']['text']+ adversarial_samples\n",
    "combined_labels = original_labels + original_labels\n",
    "\n",
    "# 7. åˆ’åˆ†æ•°æ®é›†ä¸ºè®­ç»ƒé›†å’ŒéªŒè¯é›†\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(combined_texts, combined_labels, test_size=0.1)\n",
    "\n",
    "# 8. ç¼–ç æ•°æ®\n",
    "train_encodings = bert_tokenizer(train_texts, truncation=True, padding=True, max_length=512)\n",
    "val_encodings = bert_tokenizer(val_texts, truncation=True, padding=True, max_length=512)\n",
    "\n",
    "# 9. åˆ›å»ºæ•°æ®é›†ç±»\n",
    "class IMDbDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "# 10. åˆ›å»ºè®­ç»ƒå’ŒéªŒè¯æ•°æ®é›†\n",
    "train_dataset = IMDbDataset(train_encodings, train_labels)\n",
    "val_dataset = IMDbDataset(val_encodings, val_labels)\n",
    "\n",
    "# 11. å®šä¹‰è®­ç»ƒå‚æ•°\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results/adversarial_model',\n",
    "    num_train_epochs=3,               # å¢åŠ è®­ç»ƒè½®æ•°\n",
    "    per_device_train_batch_size=32,   # å¢åŠ æ‰¹é‡å¤§å°\n",
    "    per_device_eval_batch_size=64,    # å¢åŠ è¯„ä¼°æ‰¹é‡å¤§å°\n",
    "    warmup_steps=500,                  # å¢åŠ é¢„çƒ­æ­¥æ•°\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=20,                  # å¢åŠ æ—¥å¿—è®°å½•é¢‘ç‡\n",
    "    evaluation_strategy=\"epoch\",       # æ¯ä¸ªepochè¿›è¡Œè¯„ä¼°\n",
    "    save_steps=1000,                   # å¢åŠ ä¿å­˜æ­¥æ•°\n",
    "    eval_steps=500,                    # å¢åŠ è¯„ä¼°æ­¥æ•°\n",
    "    learning_rate=5e-5,                # æ·»åŠ å­¦ä¹ ç‡å‚æ•°     \n",
    ")\n",
    "\n",
    "# 12. åˆå§‹åŒ– BERT æ¨¡å‹\n",
    "bert_model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d44d582b-d77e-4988-b73e-6e7ed9939487",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4221' max='4221' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4221/4221 58:31, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.036300</td>\n",
       "      <td>0.042059</td>\n",
       "      <td>0.987800</td>\n",
       "      <td>0.987802</td>\n",
       "      <td>0.987800</td>\n",
       "      <td>0.987800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.013400</td>\n",
       "      <td>0.041465</td>\n",
       "      <td>0.991400</td>\n",
       "      <td>0.991449</td>\n",
       "      <td>0.991400</td>\n",
       "      <td>0.991400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.028877</td>\n",
       "      <td>0.995000</td>\n",
       "      <td>0.995002</td>\n",
       "      <td>0.995000</td>\n",
       "      <td>0.995000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='79' max='79' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [79/79 00:39]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ç”Ÿæˆå¯¹æŠ—æ ·æœ¬åçš„æ¨¡å‹è¯„ä¼°ç»“æœï¼š {'eval_loss': 0.02887747250497341, 'eval_accuracy': 0.995, 'eval_precision': 0.9950019960003194, 'eval_recall': 0.995, 'eval_f1': 0.9950000030000012, 'eval_runtime': 40.3613, 'eval_samples_per_second': 123.881, 'eval_steps_per_second': 1.957, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "# 13. å®šä¹‰è®­ç»ƒå™¨\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# 14. å¼€å§‹è®­ç»ƒ\n",
    "trainer.train()\n",
    "\n",
    "# 15. è¯„ä¼°æ¨¡å‹\n",
    "adversarial_metrics = trainer.evaluate()\n",
    "print(\"ç”Ÿæˆå¯¹æŠ—æ ·æœ¬åçš„æ¨¡å‹è¯„ä¼°ç»“æœï¼š\", adversarial_metrics)\n",
    "\n",
    "# 16. å¯è§†åŒ–æ€§èƒ½å·®å¼‚ (å¦‚æœéœ€è¦)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f72cff0-46fa-447d-a09a-a5ea5fdfe94b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
